{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning Model Evaluation Lab\n",
    "\n",
    "Complete the exercises below to solidify your knowledge and understanding of supervised learning model evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "\n",
    "data = load_boston()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=['MEDV'])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `MEDV` field represents the median value of owner-occupied homes (in $1000's) and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Train a `LinearRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.17995097e-01,  4.65114582e-02,  1.97686274e-02,\n",
       "         3.64677231e+00, -1.76471698e+01,  3.84737340e+00,\n",
       "         1.11686578e-02, -1.28034274e+00,  2.73573188e-01,\n",
       "        -9.78930518e-03, -9.53524905e-01,  9.32627584e-03,\n",
       "        -5.32396003e-01]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train) #entrenamos nuestro modelo con los datos correspondientes.\n",
    "lr.intercept_ #para calcular la intersección o el valor b\n",
    "lr.coef_ # para calcular los valores correspondientes a pendientes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = lr.predict(X_test) #realizamos la prediccion utilizando los datos de prueba X_test\n",
    "y_pred_train = lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate and print R-squared for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 for the testing set is:  0.6798564653625887\n",
      "R2 for the training set is:  0.757828868200361\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "print(\"R2 for the testing set is: \", r2_score(y_test,y_pred_test))\n",
    "print(\"R2 for the training set is: \", r2_score(y_train,y_pred_train))\n",
    "\n",
    "#another way of obtaining it: \n",
    "#print(\"R2 for the testing set is: \", lr.score(X_test, y_test))\n",
    "#print(\"R2 for the training set is: \", lr.score(X_train, y_train))\n",
    "\n",
    "# lr.score devuelve el resultado de la estadistica R al cuadrado. \n",
    "# Este valor, cuanto más cercano a 1, mejor será nuestro modelo.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Calculate and print mean squared error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean squared error (test):  34.866997290976926\n",
      "Root mean squared error (train):  18.871680304544057\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score \n",
    "\n",
    "rmse_test = mean_squared_error(y_test, y_pred_test)\n",
    "rmse_train = mean_squared_error(y_train, y_pred_train)\n",
    "print(\"Root mean squared error (test): \",rmse_test)\n",
    "print(\"Root mean squared error (train): \",rmse_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Calculate and print mean absolute error for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Root mean absolute error (test):  4.215699222354452\n",
      "Root mean absolute error (train):  3.0068738726951874\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "rmae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "rmae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "print(\"Root mean absolute error (test): \",rmae_test)\n",
    "print(\"Root mean absolute error (train): \",rmae_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal length (cm)</th>\n",
       "      <th>sepal width (cm)</th>\n",
       "      <th>petal length (cm)</th>\n",
       "      <th>petal width (cm)</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
       "0                5.1               3.5                1.4               0.2   \n",
       "1                4.9               3.0                1.4               0.2   \n",
       "2                4.7               3.2                1.3               0.2   \n",
       "3                4.6               3.1                1.5               0.2   \n",
       "4                5.0               3.6                1.4               0.2   \n",
       "\n",
       "   class  \n",
       "0      0  \n",
       "1      0  \n",
       "2      0  \n",
       "3      0  \n",
       "4      0  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "data = load_iris()\n",
    "\n",
    "X = pd.DataFrame(data[\"data\"], columns=data[\"feature_names\"])\n",
    "y = pd.DataFrame(data[\"target\"], columns=[\"class\"])\n",
    "\n",
    "data = pd.concat([X, y], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split this data set into training (80%) and testing (20%) sets.\n",
    "\n",
    "The `class` field represents the type of flower and is the target variable that we will want to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Train a `LogisticRegression` model on this data set and generate predictions on both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/site-packages/sklearn/utils/validation.py:72: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n",
      "/usr/local/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.43437718,  0.87233474, -2.35234734, -1.00095676],\n",
       "       [ 0.54462096, -0.39638668, -0.20998801, -0.80896874],\n",
       "       [-0.11024378, -0.47594806,  2.56233535,  1.80992551]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "lr.intercept_\n",
    "lr.coef_\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = lr.predict(X_test)\n",
    "y_pred_train = lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Calculate and print the accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score for the test is:  1.0\n",
      "Accuracy score for the training is:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc_test= accuracy_score(y_test, y_pred_test) \n",
    "acc_train= accuracy_score(y_train, y_pred_train) \n",
    "print(\"Accuracy score for the test is: \", acc_test)\n",
    "print(\"Accuracy score for the training is: \", acc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Calculate and print the balanced accuracy score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy score for the test is:  1.0\n",
      "Balanced Accuracy score for the training is:  0.9670731707317074\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "balanced_acc_test= balanced_accuracy_score(y_test, y_pred_test) \n",
    "balanced_acc_train= balanced_accuracy_score(y_train, y_pred_train) \n",
    "print(\"Balanced Accuracy score for the test is: \", balanced_acc_test)\n",
    "print(\"Balanced Accuracy score for the training is: \", balanced_acc_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Calculate and print the precision score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision score for the test is:  1.0\n",
      "Precision score for the training is:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "\n",
    "precision_score_test= precision_score(y_test, y_pred_test, average='weighted' ) \n",
    "precision_score_train= precision_score(y_train, y_pred_train, average='weighted' ) \n",
    "print(\"Precision score for the test is: \", precision_score_test)\n",
    "print(\"Precision score for the training is: \", precision_score_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Calculate and print the recall score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall score for the test is:  1.0\n",
      "Recall score for the training is:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score\n",
    "\n",
    "recall_score_test= recall_score(y_test, y_pred_test, average='weighted' ) \n",
    "recall_score_train= recall_score(y_train, y_pred_train, average='weighted' ) \n",
    "print(\"Recall score for the test is: \", recall_score_test)\n",
    "print(\"Recall score for the training is: \", recall_score_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Calculate and print the F1 score for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "f1 score for the test is:  1.0\n",
      "f1 score for the training is:  0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1_score_test= f1_score(y_test, y_pred_test, average='weighted' ) \n",
    "f1_score_train= f1_score(y_train, y_pred_train, average='weighted' ) \n",
    "print(\"f1 score for the test is: \", f1_score_test)\n",
    "print(\"f1 score for the training is: \", f1_score_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Generate confusion matrices for both the training and the testing set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion_matrix for the test is:  [[11  0  0]\n",
      " [ 0  9  0]\n",
      " [ 0  0 10]]\n",
      "Confusion_matrix for the training is:  [[39  0  0]\n",
      " [ 0 39  2]\n",
      " [ 0  2 38]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_test= confusion_matrix(y_test, y_pred_test) \n",
    "conf_train= confusion_matrix(y_train, y_pred_train) \n",
    "print(\"Confusion_matrix for the test is: \", conf_test)\n",
    "print(\"Confusion_matrix for the training is: \", conf_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus: For each of the data sets in this lab, try training with some of the other models you have learned about, recalculate the evaluation metrics, and compare to determine which models perform best on each data set."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
